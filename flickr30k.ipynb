{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np  \n",
    "# data processing, CSV file I / O (e.g. pd.read_csv)\n",
    "import pandas as pd  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, LSTM, Dropout, Embedding, Activation\n",
    "from keras.layers import concatenate, BatchNormalization, Input\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import matplotlib.pyplot as plt  # for plotting data\n",
    "import string\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two young guys with shaggy hair look at their hands while hanging out in the yard .', 'Two young , White males are outside near many bushes .', 'Two men in green shirts are standing in a yard .', 'A man in a blue shirt standing in a garden .', 'Two friends enjoy time spent together .']\n"
     ]
    }
   ],
   "source": [
    "def load_description(text):\n",
    "    mapping = dict()\n",
    "    for line in text.split(\"\\n\"):\n",
    "        token = line.rsplit(\"| \", 1)\n",
    "        if len(line) < 2:   # remove short descriptions\n",
    "            continue\n",
    "        img_id = token[0].split('.')[0] # name of the image\n",
    "        img_des = token[1]              # description of the image\n",
    "        if img_id not in mapping:\n",
    "            mapping[img_id] = list()\n",
    "        mapping[img_id].append(img_des)\n",
    "    return mapping\n",
    "token_path = 'results.txt'\n",
    "text = open(token_path, 'r', encoding = 'utf-8').read()\n",
    "descriptions = load_description(text)\n",
    "print(descriptions['1000092795'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two young guys with shaggy hair look at their hands while hanging out in the yard',\n",
       " 'two young white males are outside near many bushes',\n",
       " 'two men in green shirts are standing in yard',\n",
       " 'man in blue shirt standing in garden',\n",
       " 'two friends enjoy time spent together']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "def clean_description(desc):\n",
    "    for key, des_list in desc.items():\n",
    "        for i in range(len(des_list)):\n",
    "            caption = des_list[i]\n",
    "            caption = [ch for ch in caption if ch not in string.punctuation]\n",
    "            caption = ''.join(caption)\n",
    "            caption = caption.split(' ')\n",
    "            caption = [word.lower() for word in caption if len(word)>1 and word.isalpha()]\n",
    "            caption = ' '.join(caption)\n",
    "            des_list[i] = caption\n",
    "\n",
    "clean_description(descriptions)\n",
    "descriptions['1000092795']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vocab(desc):\n",
    "    words = set()\n",
    "    for key in desc.keys():\n",
    "        for line in desc[key]:\n",
    "            words.update(line.split())\n",
    "    return words\n",
    "vocab = to_vocab(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['startseq two young guys with shaggy hair look at their hands while hanging out in the yard endseq', 'startseq two young white males are outside near many bushes endseq', 'startseq two men in green shirts are standing in yard endseq', 'startseq man in blue shirt standing in garden endseq', 'startseq two friends enjoy time spent together endseq']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "images = 'flickr30k_images'\n",
    "# Create a list of all image names in the directory\n",
    "img = glob.glob(images + '*.jpg')\n",
    "  \n",
    "train_path = 'flickr30k_images_des.txt'\n",
    "train_images = open(train_path, 'r', encoding = 'utf-8').read().split(\"\\n\")\n",
    "train_img = []  # list of all images in training set\n",
    "for im in img:\n",
    "    if(im[len(images):] in train_images):\n",
    "        train_img.append(im)\n",
    "          \n",
    "# load descriptions of training set in a dictionary. Name of the image will act as ey\n",
    "def load_clean_descriptions(des, dataset):\n",
    "    dataset_des = dict()\n",
    "    for key, des_list in des.items():\n",
    "        if key+'.jpg' in dataset:\n",
    "            if key not in dataset_des:\n",
    "                dataset_des[key] = list()\n",
    "            for line in des_list:\n",
    "                desc = 'startseq ' + line + ' endseq'\n",
    "                dataset_des[key].append(desc)\n",
    "    return dataset_des\n",
    "  \n",
    "train_descriptions = load_clean_descriptions(descriptions, train_images)\n",
    "print(train_descriptions['1000092795'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be6cb1895b5507ada022fe45dfc81dec8f03c89a49d478e440c6f00da1590a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
